{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74022af0-8738-4ebd-9f82-5c845e44b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import datetime\n",
    "\n",
    "RANDOM_SEED=68\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794dea3d-36a3-4c0f-9f5e-2a11a052b54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 10:52:20.446663: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-18 10:52:21.465855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6642 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2022-03-18 10:52:21.466577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6659 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# all the caches are default to /tmp/tfhub_modules\n",
    "#preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_zh_preprocess/3\")  #https://tfhub.dev/tensorflow/bert_zh_preprocess/3\n",
    "preprocessor = hub.load(\"https://tfhub.dev/tensorflow/bert_zh_preprocess/3\")\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/4\",trainable=True)  #https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b05c5-29a6-40c4-87bc-732e90145ff9",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "### 数据:CLUE Fine-Grain NER   https://www.cluebenchmarks.com/introduce.html\n",
    "\n",
    "地址（address），ADD\n",
    "书名（book），BOOK\n",
    "公司（company），COM\n",
    "游戏（game），GA\n",
    "政府（goverment），GOV\n",
    "电影（movie），MOV\n",
    "姓名（name），NAME\n",
    "组织机构（organization），ORG\n",
    "职位（position），POS\n",
    "景点（scene）SCENE\n",
    "\n",
    "使用B I 标注方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e88795-b20f-4576-9907-059b3c642e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"text\": \"浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，\", \"label\": {\"name\": {\"叶老桂\": [[9, 11]]}, \"company\": {\"浙商银行\": [[0, 3]]}}}\n",
    "sentences=[]\n",
    "labels=[]\n",
    "label_set=set()\n",
    "with open('train.json') as f:\n",
    "    for l in f.readlines():\n",
    "        data = json.loads(l)\n",
    "        text = data['text']\n",
    "        label = ['O' for _ in text]\n",
    "        for label_name,label_dict in data['label'].items():\n",
    "            label_set.add(label_name)\n",
    "            for _,pos_list in label_dict.items():\n",
    "                for s,e in pos_list:\n",
    "                    is_first = True\n",
    "                    for i in range(s,e+1):\n",
    "                        label[i] = label_name+'-'+ ('B' if is_first else \"I\")\n",
    "                        is_first=False\n",
    "        \n",
    "        sentences.append(text)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5efc55b-1e90-4616-87d5-2b0524b08350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子平均长度 37.38034983252698\n",
      "句子最大长度 50\n"
     ]
    }
   ],
   "source": [
    "print('句子平均长度',sum([len(label) for label in  labels])/len(labels))\n",
    "print('句子最大长度',max([len(label) for label in  labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca6e10a-b482-43e3-8d20-ed28df6deeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里我们选取55作为模型最大长度\n",
    "MAX_LEN=55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3256dbbb-f92b-48be-9e1b-33b6dbbe4b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'scene-B',\n",
       " 1: 'scene-I',\n",
       " 2: 'company-B',\n",
       " 3: 'company-I',\n",
       " 4: 'organization-B',\n",
       " 5: 'organization-I',\n",
       " 6: 'government-B',\n",
       " 7: 'government-I',\n",
       " 8: 'address-B',\n",
       " 9: 'address-I',\n",
       " 10: 'movie-B',\n",
       " 11: 'movie-I',\n",
       " 12: 'name-B',\n",
       " 13: 'name-I',\n",
       " 14: 'game-B',\n",
       " 15: 'game-I',\n",
       " 16: 'book-B',\n",
       " 17: 'book-I',\n",
       " 18: 'position-B',\n",
       " 19: 'position-I',\n",
       " 20: 'O'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_label_dict={}\n",
    "i=0\n",
    "for label_name in label_set:\n",
    "    id_label_dict[i]=label_name+'-B'\n",
    "    i+=1\n",
    "    id_label_dict[i]=label_name+'-I'\n",
    "    i+=1\n",
    "\n",
    "id_label_dict[i]='O'\n",
    "label_id_dict = {v:k for k,v in id_label_dict.items()}\n",
    "CLASS_NUM=len(id_label_dict)\n",
    "id_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a59ccf9-1951-44be-897d-fcc738b94f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_to_tensor(labels,max_len=MAX_LEN,label_id_dict=label_id_dict):\n",
    "    for label in labels:\n",
    "        pad = max_len-len(label)-1  # should add O at the start of sentence\n",
    "        label.insert(0,'O')\n",
    "        label.extend('O'*pad)\n",
    "        label = label[:MAX_LEN]\n",
    "        label[-1]='O'\n",
    "    labels_id = tf.constant([[label_id_dict[l] for l in label] for label in labels])\n",
    "    # onehot_labels_id = tf.one_hot(labels_id,depth=21,axis=2)\n",
    "    return labels_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3417a40-88c3-4bca-9568-329fed3cd4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tensor = tf.convert_to_tensor(sentences)\n",
    "label_tensor = convert_labels_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "439d1ba0-3b9d-4b95-9567-cf74f68abcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(l) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf9e5521-8d64-4e08-824d-2d865cf5d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"text\": \"浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，\", \"label\": {\"name\": {\"叶老桂\": [[9, 11]]}, \"company\": {\"浙商银行\": [[0, 3]]}}}\n",
    "dev_sentences=[]\n",
    "dev_labels=[]\n",
    "with open('dev.json') as f:\n",
    "    for l in f.readlines():\n",
    "        data = json.loads(l)\n",
    "        text = data['text']\n",
    "        label = ['O' for _ in text]\n",
    "        for label_name,label_dict in data['label'].items():\n",
    "            for _,pos_list in label_dict.items():\n",
    "                for s,e in pos_list:\n",
    "                    is_first = True\n",
    "                    for i in range(s,e+1):\n",
    "                        label[i] = label_name+'-'+ ('B' if is_first else \"I\")\n",
    "                        is_first=False\n",
    "        \n",
    "        dev_sentences.append(text)\n",
    "        dev_labels.append(label)\n",
    "dev_label_tensor = convert_labels_to_tensor(dev_labels)\n",
    "dev_sentences_tensor = tf.convert_to_tensor(dev_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e94a07-ade4-458a-b063-690fa7aee929",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = hub.KerasLayer(preprocessor.tokenize)\n",
    "l2 = hub.KerasLayer(preprocessor.bert_pack_inputs,arguments=dict(seq_length=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ac1484-3663-49ca-94f6-361fae073981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    encoder_inputs = l1(text_input)\n",
    "    encoder_inputs = l2([encoder_inputs])\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['sequence_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    potential_logits = tf.keras.layers.Dense(CLASS_NUM, activation=None, name='classifier')(net)\n",
    "    decoded_sequence, potentials, sequence_length, chain_kernel = tfa.layers.CRF(units=CLASS_NUM,use_kernel=False)(potential_logits)\n",
    "    return tf.keras.Model(text_input, [decoded_sequence, potentials, sequence_length, chain_kernel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a369a9e-bce3-4c0d-a0ee-8536c3b59c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     (None, None, None)   0           ['text[0][0]']                   \n",
      "                                                                                                  \n",
      " keras_layer_2 (KerasLayer)     {'input_mask': (Non  0           ['keras_layer_1[0][0]']          \n",
      "                                e, 55),                                                           \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 55),                                                       \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 55)}                                                       \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'sequence_output':  102267649   ['keras_layer_2[0][0]',          \n",
      "                                 (None, 55, 768),                 'keras_layer_2[0][1]',          \n",
      "                                 'default': (None,                'keras_layer_2[0][2]']          \n",
      "                                768),                                                             \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 55, 768),                                                \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768),                                                 \n",
      "                                 (None, 55, 768)]}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 55, 768)      0           ['keras_layer[0][14]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 55, 21)       16149       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " crf (CRF)                      [(None, 55),         483         ['classifier[0][0]']             \n",
      "                                 (None, 55, 21),                                                  \n",
      "                                 (None,),                                                         \n",
      "                                 (21, 21)]                                                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 102,284,281\n",
      "Trainable params: 102,284,280\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_classifier_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c344238-4e43-4175-8df8-8ea0b8da7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((sentences_tensor,label_tensor))\n",
    "dev_ds = tf.data.Dataset.from_tensor_slices((dev_sentences_tensor,dev_label_tensor))\n",
    "batched_train_ds = train_ds.shuffle(1000).batch(16)\n",
    "batched_dev_ds = dev_ds.batch(32)\n",
    "optimizer = tf.keras.optimizers.Adam(2e-5)\n",
    "m = tf.keras.metrics.Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de4bb86-a75b-474d-985f-9415e1e5170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function # take tensor 作为输入的函数可以使用静态图优化\n",
    "def train_step(x_batch,y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        out = model(x_batch,training=True)\n",
    "        decoded_sequence, potentials, sequence_length, chain_kernel = out\n",
    "        losses = -tfa.text.crf_log_likelihood(potentials, y_batch, sequence_length, chain_kernel)[0] #似然大致可以理解成概率，对数不改变符号方向，我们希望正确的概率越大越好\n",
    "        loss = tf.reduce_mean(losses)\n",
    "\n",
    "    grads = tape.gradient(loss,model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
    "    m.update_state(decoded_sequence, y_batch)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def test_step(x_batch_val,y_batch_val):\n",
    "    val_decoded_sequence, _, _, _ = model(x_batch_val, training=False)\n",
    "    m.update_state(y_batch_val, val_decoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52e4899b-0f8f-4d75-be83-31f4a8d1101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 10:52:46.741876: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/branch_executed/_1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-18 10:52:49.928500 - 0-0 loss: 171.75064086914062\n",
      "2022-03-18 10:53:28.179889 - 0-200 loss: 22.44293212890625\n",
      "2022-03-18 10:54:06.528936 - 0-400 loss: 18.585840225219727\n",
      "2022-03-18 10:54:44.928932 - 0-600 loss: 19.53022575378418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 10:55:03.991768: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond_1/branch_executed/_1384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc on epoch 0 is: 0.8942044377326965\n",
      "VAL acc on epoch 0 is: 0.9260001182556152\n",
      "2022-03-18 10:55:15.909097 - 1-0 loss: 13.712574005126953\n",
      "2022-03-18 10:55:54.366822 - 1-200 loss: 13.386499404907227\n",
      "2022-03-18 10:56:32.795324 - 1-400 loss: 9.843090057373047\n",
      "2022-03-18 10:57:11.054718 - 1-600 loss: 7.803056716918945\n",
      "training acc on epoch 1 is: 0.9291978478431702\n",
      "VAL acc on epoch 1 is: 0.9304677248001099\n",
      "2022-03-18 10:57:31.733265 - 2-0 loss: 12.836954116821289\n",
      "2022-03-18 10:58:10.194211 - 2-200 loss: 11.2840576171875\n",
      "2022-03-18 10:58:48.520130 - 2-400 loss: 8.996906280517578\n",
      "2022-03-18 10:59:26.990509 - 2-600 loss: 6.702487945556641\n",
      "training acc on epoch 2 is: 0.943480372428894\n",
      "VAL acc on epoch 2 is: 0.9321870803833008\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for step, (x_batch,y_batch) in enumerate(batched_train_ds):\n",
    "        loss = train_step(x_batch,y_batch)\n",
    "        if step%200==0:\n",
    "            print(f'{datetime.datetime.now()} - {epoch}-{step} loss: {loss}')\n",
    "        \n",
    "    epoch_acc = m.result()\n",
    "    m.reset_states()\n",
    "    print(f'training acc on epoch {epoch} is: {epoch_acc}')\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in batched_dev_ds:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "        \n",
    "    val_epoch_acc = m.result()\n",
    "    print(f'VAL acc on epoch {epoch} is: {val_epoch_acc}')\n",
    "    m.reset_states()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2629b85-4e09-43b0-9b71-c74f7ffa9dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子 生生不息CSOL生化狂潮让你填弹狂扫\n",
      "label ['O', 'O', 'O', 'O', 'O', 'game-B', 'game-I', 'game-I', 'game-I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O,O,O,O,O,game-B,game-I,game-I,game-I,game-I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看一下第i条数据的结果\n",
    "i=1\n",
    "output = model.predict([sentences[i]])[0]\n",
    "print('句子',sentences[i])\n",
    "print('label',labels[i])\n",
    "','.join([ id_label_dict[i] for i in  output[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de2e81a6-6128-4f1d-9775-187dcab284e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-18 11:00:05.704831 - 0-0 loss: 6.388515472412109\n",
      "2022-03-18 11:01:48.147187 - 0-200 loss: 6.950614929199219\n",
      "2022-03-18 11:03:31.104976 - 0-400 loss: 3.645936965942383\n",
      "2022-03-18 11:05:13.852246 - 0-600 loss: 12.634344100952148\n",
      "training acc on epoch 0 is: 0.9539449214935303\n",
      "VAL acc on epoch 0 is: 0.9376835823059082\n",
      "2022-03-18 11:06:10.595539 - 1-0 loss: 8.483667373657227\n",
      "2022-03-18 11:07:53.323358 - 1-200 loss: 7.234052658081055\n",
      "2022-03-18 11:09:36.503812 - 1-400 loss: 5.007223129272461\n",
      "2022-03-18 11:11:19.132952 - 1-600 loss: 6.304544448852539\n",
      "training acc on epoch 1 is: 0.9609652757644653\n",
      "VAL acc on epoch 1 is: 0.9372910261154175\n",
      "2022-03-18 11:12:06.829385 - 2-0 loss: 6.307212829589844\n",
      "2022-03-18 11:13:49.756716 - 2-200 loss: 4.997684478759766\n",
      "2022-03-18 11:15:32.301416 - 2-400 loss: 1.9620513916015625\n",
      "2022-03-18 11:17:14.463546 - 2-600 loss: 3.554637908935547\n",
      "training acc on epoch 2 is: 0.9674002528190613\n",
      "VAL acc on epoch 2 is: 0.9336763024330139\n"
     ]
    }
   ],
   "source": [
    "#看一下不做静态图优化的速度\n",
    "def train_step(x_batch,y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        out = model(x_batch,training=True)\n",
    "        decoded_sequence, potentials, sequence_length, chain_kernel = out\n",
    "        losses = -tfa.text.crf_log_likelihood(potentials, y_batch, sequence_length, chain_kernel)[0] #似然大致可以理解成概率，对数不改变符号方向，我们希望正确的概率越大越好\n",
    "        loss = tf.reduce_mean(losses)\n",
    "\n",
    "    grads = tape.gradient(loss,model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
    "    m.update_state(decoded_sequence, y_batch)\n",
    "    return loss\n",
    "\n",
    "def test_step(x_batch_val,y_batch_val):\n",
    "    val_decoded_sequence, _, _, _ = model(x_batch_val, training=False)\n",
    "    m.update_state(y_batch_val, val_decoded_sequence)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for step, (x_batch,y_batch) in enumerate(batched_train_ds):\n",
    "        loss = train_step(x_batch,y_batch)\n",
    "        if step%200==0:\n",
    "            print(f'{datetime.datetime.now()} - {epoch}-{step} loss: {loss}')\n",
    "        \n",
    "    epoch_acc = m.result()\n",
    "    m.reset_states()\n",
    "    print(f'training acc on epoch {epoch} is: {epoch_acc}')\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in batched_dev_ds:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "        \n",
    "    val_epoch_acc = m.result()\n",
    "    print(f'VAL acc on epoch {epoch} is: {val_epoch_acc}')\n",
    "    m.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba87fd-56d0-4f61-8d73-f90a51d5aa55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
