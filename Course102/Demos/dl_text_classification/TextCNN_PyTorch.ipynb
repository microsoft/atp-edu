{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec2f6f4d-fa84-4ae8-a19d-372e15118e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda for training\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from process import *\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"using {device} for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1cbc83-3b1e-4f07-bce2-23a2205bf1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从原始数据准备训练用的csv数据\n",
    "#def prepare_data(train_data_origin_path, train_data_path, sampled_label=None):\n",
    "#     df = pd.read_json(train_data_origin_path, lines=True)\n",
    "#     # df = df.loc[df['label'].isin(sampled_label)]\n",
    "#     df.to_csv(train_data_path, encoding='utf-8')\n",
    "#     return df\n",
    "# prepare_data('data/train.json','data/train.csv')\n",
    "# prepare_data('data/dev.json','data/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb69dd2b-da9b-435e-a3dc-0c36bb93b82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == loading word embedding\n",
      "word embedding vocab loaded\n"
     ]
    }
   ],
   "source": [
    "lens=23\n",
    "embedding_path = './embedding_models/tencent-ailab-embedding-zh-d100-v0.2.0-s/tencent-ailab-embedding-zh-d100-v0.2.0-s.txt'\n",
    "print(\" == loading word embedding\")\n",
    "vectors, size, dim = load_embeddings(embedding_path)\n",
    "vectors['OOV'] = np.random.rand(dim)\n",
    "vectors['PAD'] = np.zeros(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce200d79-4778-4c92-850a-65e0856b91cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.689 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "dev_data = pd.read_csv('./data/dev.csv')\n",
    "sentences = train_data['sentence'].values.tolist()\n",
    "sentences_embedded = [vectorize(sentence=sentence, length=lens, padding='PAD', oov='OOV', vectors=vectors)\n",
    "                      for sentence in sentences]\n",
    "\n",
    "sentences_embedded = np.array(sentences_embedded)\n",
    "sentences_embedded = sentences_embedded.reshape(len(train_data), lens, dim, 1)\n",
    "\n",
    "labels = train_data['label'].values.tolist()\n",
    "label_set = set(labels)\n",
    "label_map = {}\n",
    "for i, key in enumerate(label_set):\n",
    "    label_map[key] = i\n",
    "labels_mapped = np.array([label_map[label] for label in labels])\n",
    "\n",
    "# load dev data\n",
    "dev_sentences = dev_data['sentence'].values.tolist()\n",
    "dev_sentences_embedded = [vectorize(sentence=sentence, length=lens, padding='PAD', oov='OOV', vectors=vectors)\n",
    "                      for sentence in dev_sentences]\n",
    "\n",
    "dev_sentences_embedded = np.array(dev_sentences_embedded)\n",
    "dev_sentences_embedded = dev_sentences_embedded.reshape(len(dev_data), lens, dim, 1)\n",
    "\n",
    "dev_labels = dev_data['label'].values.tolist()\n",
    "dev_labels_mapped = np.array([label_map[label] for label in dev_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0997fd5e-711d-484d-b0dc-d371637a1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(sentences_embedded,dtype=torch.float).permute(0,3,1,2),torch.tensor(labels_mapped,dtype=torch.long))\n",
    "dev_dataset = TensorDataset(torch.tensor(dev_sentences_embedded,dtype=torch.float).permute(0,3,1,2),torch.tensor(dev_labels_mapped,dtype=torch.long))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256,\n",
    "                                         shuffle=True)\n",
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=256,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a8eb1-232e-4991-8e9f-3ce2b81a913f",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ab5be9-bc38-415a-bace-ed06f7cf52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class textCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_class,emb_dim=100):\n",
    "        super(textCNN, self).__init__()\n",
    "    \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, 32, (w, emb_dim)) for w in [4,5,6,7]])\n",
    "        self.conv_dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4*32,64)\n",
    "        self.fc_dropout = nn.Dropout(0.6)\n",
    "        self.fc2 = nn.Linear(64, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        con_x = [self.conv_dropout(F.relu(conv(x))) for conv in self.convs]\n",
    "\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]\n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1)\n",
    "        \n",
    "        fc_x = fc_x.squeeze(-1)\n",
    "        fc_x = F.relu(self.fc1(fc_x))\n",
    "        fc_x = self.fc_dropout(fc_x)\n",
    "        logit = self.fc2(fc_x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c3cda72-c0d3-4b6e-88ec-4bfa8b14a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = textCNN(15).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cbcd4ec-552b-4436-9f77-bf462c063c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1-0050: loss: 2.3473; accuracy:0.1497\n",
      " 1-0100: loss: 1.9828; accuracy:0.2273\n",
      " 1-0150: loss: 1.8125; accuracy:0.2814\n",
      " 1-0200: loss: 1.8869; accuracy:0.3189\n",
      "accuracy on valid set :0.528\n",
      " 2-0050: loss: 1.6059; accuracy:0.4593\n",
      " 2-0100: loss: 1.6283; accuracy:0.4691\n",
      " 2-0150: loss: 1.6090; accuracy:0.4717\n",
      " 2-0200: loss: 1.5761; accuracy:0.4766\n",
      "accuracy on valid set :0.547\n",
      " 3-0050: loss: 1.6332; accuracy:0.4939\n",
      " 3-0100: loss: 1.5843; accuracy:0.5046\n",
      " 3-0150: loss: 1.4423; accuracy:0.5066\n",
      " 3-0200: loss: 1.4960; accuracy:0.5083\n",
      "accuracy on valid set :0.558\n",
      " 4-0050: loss: 1.5496; accuracy:0.5188\n",
      " 4-0100: loss: 1.4704; accuracy:0.5215\n",
      " 4-0150: loss: 1.5301; accuracy:0.5212\n",
      " 4-0200: loss: 1.6085; accuracy:0.5218\n",
      "accuracy on valid set :0.563\n",
      " 5-0050: loss: 1.4572; accuracy:0.5293\n",
      " 5-0100: loss: 1.5084; accuracy:0.5314\n",
      " 5-0150: loss: 1.4211; accuracy:0.5309\n",
      " 5-0200: loss: 1.4810; accuracy:0.5310\n",
      "accuracy on valid set :0.568\n",
      " 6-0050: loss: 1.6412; accuracy:0.5424\n",
      " 6-0100: loss: 1.4275; accuracy:0.5446\n",
      " 6-0150: loss: 1.3639; accuracy:0.5451\n",
      " 6-0200: loss: 1.4033; accuracy:0.5429\n",
      "accuracy on valid set :0.566\n",
      " 7-0050: loss: 1.3604; accuracy:0.5524\n",
      " 7-0100: loss: 1.4642; accuracy:0.5503\n",
      " 7-0150: loss: 1.3352; accuracy:0.5486\n",
      " 7-0200: loss: 1.5002; accuracy:0.5464\n",
      "accuracy on valid set :0.571\n",
      " 8-0050: loss: 1.5229; accuracy:0.5559\n",
      " 8-0100: loss: 1.2924; accuracy:0.5538\n",
      " 8-0150: loss: 1.4947; accuracy:0.5514\n",
      " 8-0200: loss: 1.4303; accuracy:0.5519\n",
      "accuracy on valid set :0.569\n",
      " 9-0050: loss: 1.4797; accuracy:0.5559\n",
      " 9-0100: loss: 1.3979; accuracy:0.5561\n",
      " 9-0150: loss: 1.2915; accuracy:0.5590\n",
      " 9-0200: loss: 1.2264; accuracy:0.5574\n",
      "accuracy on valid set :0.572\n",
      "10-0050: loss: 1.2305; accuracy:0.5636\n",
      "10-0100: loss: 1.4218; accuracy:0.5611\n",
      "10-0150: loss: 1.4167; accuracy:0.5595\n",
      "10-0200: loss: 1.2054; accuracy:0.5612\n",
      "accuracy on valid set :0.574\n",
      "11-0050: loss: 1.3201; accuracy:0.5665\n",
      "11-0100: loss: 1.3166; accuracy:0.5686\n",
      "11-0150: loss: 1.1885; accuracy:0.5674\n",
      "11-0200: loss: 1.2770; accuracy:0.5641\n",
      "accuracy on valid set :0.569\n",
      "12-0050: loss: 1.2745; accuracy:0.5593\n",
      "12-0100: loss: 1.2661; accuracy:0.5670\n",
      "12-0150: loss: 1.3988; accuracy:0.5667\n",
      "12-0200: loss: 1.2891; accuracy:0.5693\n",
      "accuracy on valid set :0.571\n",
      "13-0050: loss: 1.3849; accuracy:0.5801\n",
      "13-0100: loss: 1.2727; accuracy:0.5772\n",
      "13-0150: loss: 1.3916; accuracy:0.5746\n",
      "13-0200: loss: 1.2554; accuracy:0.5726\n",
      "accuracy on valid set :0.571\n",
      "14-0050: loss: 1.1578; accuracy:0.5771\n",
      "14-0100: loss: 1.2075; accuracy:0.5818\n",
      "14-0150: loss: 1.4140; accuracy:0.5793\n",
      "14-0200: loss: 1.1217; accuracy:0.5776\n",
      "accuracy on valid set :0.570\n",
      "15-0050: loss: 1.2256; accuracy:0.5785\n",
      "15-0100: loss: 1.2198; accuracy:0.5788\n",
      "15-0150: loss: 1.2827; accuracy:0.5812\n",
      "15-0200: loss: 1.1668; accuracy:0.5812\n",
      "accuracy on valid set :0.572\n",
      "16-0050: loss: 1.2793; accuracy:0.5835\n",
      "16-0100: loss: 1.2046; accuracy:0.5822\n",
      "16-0150: loss: 1.2281; accuracy:0.5781\n",
      "16-0200: loss: 1.1812; accuracy:0.5795\n",
      "accuracy on valid set :0.573\n",
      "17-0050: loss: 1.1119; accuracy:0.5869\n",
      "17-0100: loss: 1.2549; accuracy:0.5881\n",
      "17-0150: loss: 1.1642; accuracy:0.5844\n",
      "17-0200: loss: 1.3351; accuracy:0.5835\n",
      "accuracy on valid set :0.571\n",
      "18-0050: loss: 1.3218; accuracy:0.5911\n",
      "18-0100: loss: 1.2289; accuracy:0.5922\n",
      "18-0150: loss: 1.0570; accuracy:0.5916\n",
      "18-0200: loss: 1.1866; accuracy:0.5896\n",
      "accuracy on valid set :0.573\n",
      "19-0050: loss: 1.2172; accuracy:0.5982\n",
      "19-0100: loss: 1.2055; accuracy:0.5939\n",
      "19-0150: loss: 1.1652; accuracy:0.5921\n",
      "19-0200: loss: 1.1934; accuracy:0.5909\n",
      "accuracy on valid set :0.573\n",
      "20-0050: loss: 1.1239; accuracy:0.6045\n",
      "20-0100: loss: 1.1134; accuracy:0.6002\n",
      "20-0150: loss: 1.1144; accuracy:0.5987\n",
      "20-0200: loss: 1.0892; accuracy:0.5953\n",
      "accuracy on valid set :0.572\n",
      "21-0050: loss: 1.3042; accuracy:0.5993\n",
      "21-0100: loss: 1.2276; accuracy:0.5971\n",
      "21-0150: loss: 1.2958; accuracy:0.5967\n",
      "21-0200: loss: 1.1337; accuracy:0.5961\n",
      "accuracy on valid set :0.571\n",
      "22-0050: loss: 1.3574; accuracy:0.6057\n",
      "22-0100: loss: 1.2094; accuracy:0.6026\n",
      "22-0150: loss: 1.1381; accuracy:0.5992\n",
      "22-0200: loss: 1.0826; accuracy:0.5977\n",
      "accuracy on valid set :0.568\n",
      "23-0050: loss: 1.0192; accuracy:0.6084\n",
      "23-0100: loss: 1.0745; accuracy:0.6062\n",
      "23-0150: loss: 1.3075; accuracy:0.6044\n",
      "23-0200: loss: 1.0623; accuracy:0.6026\n",
      "accuracy on valid set :0.572\n",
      "24-0050: loss: 1.1266; accuracy:0.6040\n",
      "24-0100: loss: 1.3359; accuracy:0.6030\n",
      "24-0150: loss: 1.0817; accuracy:0.6019\n",
      "24-0200: loss: 1.3849; accuracy:0.6015\n",
      "accuracy on valid set :0.570\n",
      "25-0050: loss: 1.1780; accuracy:0.6127\n",
      "25-0100: loss: 1.1902; accuracy:0.6100\n",
      "25-0150: loss: 1.1640; accuracy:0.6049\n",
      "25-0200: loss: 1.2568; accuracy:0.6052\n",
      "accuracy on valid set :0.573\n",
      "26-0050: loss: 1.1366; accuracy:0.6181\n",
      "26-0100: loss: 0.9883; accuracy:0.6145\n",
      "26-0150: loss: 1.2347; accuracy:0.6106\n",
      "26-0200: loss: 0.9794; accuracy:0.6109\n",
      "accuracy on valid set :0.573\n",
      "27-0050: loss: 0.9412; accuracy:0.6122\n",
      "27-0100: loss: 1.2608; accuracy:0.6125\n",
      "27-0150: loss: 1.1917; accuracy:0.6119\n",
      "27-0200: loss: 1.0769; accuracy:0.6113\n",
      "accuracy on valid set :0.570\n",
      "28-0050: loss: 1.1651; accuracy:0.6133\n",
      "28-0100: loss: 1.1278; accuracy:0.6136\n",
      "28-0150: loss: 1.0734; accuracy:0.6102\n",
      "28-0200: loss: 1.1371; accuracy:0.6096\n",
      "accuracy on valid set :0.570\n",
      "29-0050: loss: 0.9868; accuracy:0.6114\n",
      "29-0100: loss: 1.0142; accuracy:0.6150\n",
      "29-0150: loss: 1.1919; accuracy:0.6155\n",
      "29-0200: loss: 1.1482; accuracy:0.6123\n",
      "accuracy on valid set :0.569\n",
      "30-0050: loss: 0.9439; accuracy:0.6174\n",
      "30-0100: loss: 1.2212; accuracy:0.6179\n",
      "30-0150: loss: 1.0820; accuracy:0.6188\n",
      "30-0200: loss: 1.2541; accuracy:0.6164\n",
      "accuracy on valid set :0.573\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    for idx, (x,y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        predicted_label = model(x)\n",
    "        loss = loss_func(predicted_label, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_acc += (predicted_label.argmax(1) == y).sum().item()\n",
    "        total_count += y.size(0)\n",
    "        if idx % 50 == 0 and idx > 0:\n",
    "            print(f'{epoch:2d}-{idx:04d}: loss:{loss.item():7.4f}; accuracy:{total_acc/total_count:.4f}')\n",
    "            \n",
    "    \n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(dev_dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            predicted_label = model(x)\n",
    "            loss = loss_func(predicted_label, y)\n",
    "            total_acc += (predicted_label.argmax(1) == y).sum().item()\n",
    "            total_count += y.size(0)\n",
    "    valid_acc = total_acc/total_count\n",
    "    print(f'accuracy on valid set :{valid_acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea108a87-c9bf-4b6e-a137-d0cdc96a470c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
